{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dad3832e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "\n",
    "import torch\n",
    "import torchvision\n",
    "import torch.nn as nn\n",
    "from torchvision import transforms, datasets, models\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from torch.utils.data.sampler import SubsetRandomSampler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b369f48",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_default_device():\n",
    "    if torch.cuda.is_available():\n",
    "        return torch.device('cuda')\n",
    "    elif torch.backends.mps.is_available():\n",
    "        return torch.device('mps')\n",
    "    return torch.device('cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d57a2d9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "DEVICE = get_default_device()\n",
    "BATCH_SIZE = 32\n",
    "LEARNING_RATE = 5e-3\n",
    "NUM_CLASSES = 10\n",
    "NUM_EPOCHS = 20\n",
    "CLASSES = (\n",
    "    \"plane\",\n",
    "    \"car\",\n",
    "    \"bird\",\n",
    "    \"cat\",\n",
    "    \"deer\",\n",
    "    \"dog\",\n",
    "    \"frog\",\n",
    "    \"horse\",\n",
    "    \"ship\",\n",
    "    \"truck\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2175db41",
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_loader(\n",
    "    data_dir,\n",
    "    batch_size,\n",
    "    image_size=(224, 224),\n",
    "    random_seed=47,\n",
    "    valid_size=0.1,\n",
    "    shuffle=True,\n",
    "    test=False,\n",
    "    download=True,\n",
    "):\n",
    "    data_transforms = transforms.Compose(\n",
    "        [\n",
    "            transforms.Resize(image_size),\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize(\n",
    "                mean=[0.4914, 0.4822, 0.4465], std=[0.2023, 0.1994, 0.2010]\n",
    "            ),\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    if test:\n",
    "        dataset = datasets.CIFAR10(\n",
    "            root=data_dir, train=False, transform=data_transforms, download=download\n",
    "        )\n",
    "\n",
    "        data_loader = DataLoader(\n",
    "            dataset=dataset,\n",
    "            batch_size=batch_size,\n",
    "            shuffle=shuffle,\n",
    "        )\n",
    "\n",
    "        return data_loader\n",
    "\n",
    "    train_dataset = datasets.CIFAR10(\n",
    "        root=data_dir, train=True, transform=data_transforms, download=download\n",
    "    )\n",
    "\n",
    "    valid_dataset = datasets.CIFAR10(\n",
    "        root=data_dir, train=True, transform=data_transforms, download=download\n",
    "    )\n",
    "\n",
    "    num_train = len(train_dataset)\n",
    "    indices = list(range(num_train))\n",
    "    split = int(np.floor(valid_size * num_train))\n",
    "\n",
    "    if shuffle:\n",
    "        np.random.seed(random_seed)\n",
    "        np.random.shuffle(indices)\n",
    "\n",
    "    train_indices, valid_indices = indices[split:], indices[:split]\n",
    "    train_sampler = SubsetRandomSampler(indices=train_indices)\n",
    "    valid_sampler = SubsetRandomSampler(indices=valid_indices)\n",
    "\n",
    "    train_dataloader = DataLoader(\n",
    "        dataset=train_dataset, batch_size=batch_size, sampler=train_sampler\n",
    "    )\n",
    "\n",
    "    valid_dataloader = DataLoader(\n",
    "        dataset=valid_dataset, batch_size=batch_size, sampler=valid_sampler\n",
    "    )\n",
    "\n",
    "    return (train_dataloader, valid_dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e570ede",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataloader, valid_dataloader = data_loader(\n",
    "    data_dir=\"./data\",\n",
    "    batch_size=BATCH_SIZE,\n",
    ")\n",
    "\n",
    "test_dataloader = data_loader(\n",
    "    data_dir=\"./data\",\n",
    "    batch_size=BATCH_SIZE,\n",
    "    test=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b9c3040",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # implementation from scratch\n",
    "\n",
    "# class ResidualBlock(nn.Module):\n",
    "#     def __init__(\n",
    "#         self,\n",
    "#         in_channels,\n",
    "#         out_channels,\n",
    "#         stride=1,\n",
    "#         kernel_size=(3, 3),\n",
    "#         padding=1,\n",
    "#         downsample=None,\n",
    "#     ):\n",
    "#         super(ResidualBlock, self).__init__()\n",
    "#         self.conv1 = nn.Conv2d(\n",
    "#             in_channels=in_channels,\n",
    "#             out_channels=out_channels,\n",
    "#             kernel_size=kernel_size,\n",
    "#             stride=stride,\n",
    "#             padding=padding,\n",
    "#         )\n",
    "#         self.bn1 = nn.BatchNorm2d(num_features=out_channels)\n",
    "#         self.relu = nn.ReLU(inplace=True)\n",
    "#         self.conv2 = nn.Conv2d(\n",
    "#             in_channels=out_channels,\n",
    "#             out_channels=out_channels,\n",
    "#             kernel_size=kernel_size,\n",
    "#             stride=stride,\n",
    "#             padding=padding,\n",
    "#         )\n",
    "#         self.bn2 = nn.BatchNorm2d(num_features=out_channels)\n",
    "#         self.downsample = downsample\n",
    "#         self.stride = stride\n",
    "\n",
    "#     def forward(self, x):\n",
    "#         residual = x\n",
    "#         out = self.relu(self.bn1(self.conv1(X)))\n",
    "#         out = self.bn2(self.conv2(out))\n",
    "#         if self.downsample:\n",
    "#             residual = self.downsample(x)\n",
    "#         out += residual\n",
    "#         out = self.relu(out)\n",
    "#         return out\n",
    "    \n",
    "\n",
    "# class ResNet(nn.Module):\n",
    "#     def __init__(self, block_obj, layers, in_channels=3, num_classes=1000):\n",
    "#         super(ResNet, self).__init__()\n",
    "#         self.inplanes = 64\n",
    "#         self.conv1 = nn.Conv2d(\n",
    "#             in_channels=in_channels,\n",
    "#             out_channels=64,\n",
    "#             kernel_size=7,\n",
    "#             stride=2,\n",
    "#             padding=3,\n",
    "#             bias=False,\n",
    "#         )\n",
    "#         self.bn = nn.BatchNorm2d(num_features=64)\n",
    "#         self.relu = nn.ReLU(inplace=True)\n",
    "#         self.maxpool = nn.MaxPool2d(kernel_size=3, stride=2, padding=1)\n",
    "\n",
    "#         self.layer0 = self.make_layers(\n",
    "#             block_obj=block_obj, planes=64, num_blocks=layers[0]\n",
    "#         )\n",
    "#         self.layer1 = self.make_layers(\n",
    "#             block_obj=block_obj,\n",
    "#             planes=128,\n",
    "#             num_blocks=layers[1],\n",
    "#             stride=2,\n",
    "#         )\n",
    "#         self.layer2 = self.make_layers(\n",
    "#             block_obj=block_obj,\n",
    "#             planes=256,\n",
    "#             num_blocks=layers[2],\n",
    "#             stride=2,\n",
    "#         )\n",
    "#         self.layer3 = self.make_layers(\n",
    "#             block_obj=block_obj,\n",
    "#             planes=512,\n",
    "#             num_blocks=layers[3],\n",
    "#             stride=2,\n",
    "#         )\n",
    "\n",
    "#         self.avgpool = nn.AdaptiveAvgPool2d(output_size=(1, 1))\n",
    "#         self.fc = nn.Linear(in_features=512, out_features=num_classes)\n",
    "\n",
    "#     def make_layers(self, block_obj, planes, num_blocks, stride=1):\n",
    "#         downsample = None\n",
    "#         if self.inplanes != planes or stride != 1:\n",
    "#             downsample = nn.Sequential(\n",
    "#                 nn.Conv2d(\n",
    "#                     in_channels=self.inplanes,\n",
    "#                     out_channels=planes,\n",
    "#                     kernel_size=1,\n",
    "#                     stride=stride,\n",
    "#                     bias=False,\n",
    "#                 ),\n",
    "#                 nn.BatchNorm2d(num_features=planes),\n",
    "#             )\n",
    "#         layers = []\n",
    "#         layers.append(block_obj(self.inplanes, planes, stride, downsample=downsample))\n",
    "#         self.inplanes = planes\n",
    "#         for _ in range(1, num_blocks):\n",
    "#             layers.append(block_obj(self.inplanes, planes))\n",
    "#         return nn.Sequential(*layers)\n",
    "\n",
    "#     def forward(self, x):\n",
    "#         x = self.maxpool(self.relu(self.bn(self.conv1(x))))\n",
    "#         x = self.layer0(x)\n",
    "#         x = self.layer1(x)\n",
    "#         x = self.layer2(x)\n",
    "#         x = self.layer3(x)\n",
    "#         x = self.avgpool(x)\n",
    "#         x = torch.flatten(input=x, start_dim=1)\n",
    "#         x = seff.fc(x)\n",
    "#         return x\n",
    "    \n",
    "# # resnet34 implementation\n",
    "# layers = [3, 4, 6, 3]\n",
    "# model = ResNet(ResidualBlock, layers)\n",
    "# model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18e6d0d6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model = torchvision.models.resnet34(weights=torchvision.models.ResNet34_Weights.DEFAULT, progress=True)\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a5260ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "fine_tune_model = model\n",
    "last_layer_in_features = fine_tune_model.fc.in_features\n",
    "fine_tune_model.fc = nn.Linear(in_features=last_layer_in_features, out_features=NUM_CLASSES)\n",
    "fine_tune_model.to(DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da0538bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_fn = nn.CrossEntropyLoss()\n",
    "fine_tune_optimizer = torch.optim.SGD(\n",
    "    fine_tune_model.parameters(), lr=LEARNING_RATE, weight_decay=5e-3, momentum=0.9\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4de5d9d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit_model(num_epochs, model, criterion, optimizer):\n",
    "    for epoch in range(num_epochs):\n",
    "        for idx, (images, labels) in enumerate(tqdm(train_dataloader)):\n",
    "            images = images.to(DEVICE)\n",
    "            labels = labels.to(DEVICE)\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "        print(f\"Epoch: {epoch+1}/{num_epochs} | Loss: {loss.item()}\")\n",
    "        with torch.no_grad():\n",
    "            correct = 0\n",
    "            total = 0\n",
    "            print('\\nPerforming Validation...\\n')\n",
    "            for images, labels in tqdm(valid_dataloader):\n",
    "                images = images.to(DEVICE)\n",
    "                labels = labels.to(DEVICE)\n",
    "                outputs = model(images)\n",
    "                _, predicted = torch.max(outputs.data, 1)\n",
    "                total += labels.size(0)\n",
    "                correct += (predicted == labels).sum().item()\n",
    "                del images, labels, outputs\n",
    "            print(f\"Validation Accuracy: {(correct/total)*100}\")\n",
    "            print(\"%\" * 30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d693b47",
   "metadata": {},
   "outputs": [],
   "source": [
    "# this is fine tuning i.e. training entire model from scratch but with pretrained weights\n",
    "\n",
    "fit_model(\n",
    "    num_epochs=NUM_EPOCHS,\n",
    "    model=fine_tune_model,\n",
    "    criterion=loss_fn,\n",
    "    optimizer=fine_tune_optimizer,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e299ca28",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = torchvision.models.resnet34(weights=torchvision.models.ResNet34_Weights.DEFAULT, progress=True)\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1565509",
   "metadata": {},
   "outputs": [],
   "source": [
    "for parameter in model.parameters():\n",
    "    parameter.requires_grad = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59203bd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_extraction_model = model\n",
    "last_layer_in_features = feature_extraction_model.fc.in_features\n",
    "feature_extraction_model.fc = nn.Linear(in_features=last_layer_in_features, out_features=NUM_CLASSES)\n",
    "feature_extraction_model.to(DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdad721d",
   "metadata": {},
   "outputs": [],
   "source": [
    "params_to_update = []\n",
    "for name, parameter in feature_extraction_model.named_parameters():\n",
    "    if parameter.requires_grad:\n",
    "        params_to_update.append(parameter)\n",
    "        print(name)\n",
    "print()\n",
    "print(params_to_update)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3e5e02b",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_fn = nn.CrossEntropyLoss()\n",
    "feature_extraction_optimizer = torch.optim.SGD(\n",
    "   params_to_update, lr=LEARNING_RATE, weight_decay=5e-3, momentum=0.9 \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "688e5496",
   "metadata": {},
   "outputs": [],
   "source": [
    "# this is feature extraction i.e. training last layer of the model keeping pretrained weights as it is\n",
    "\n",
    "fit_model(\n",
    "    num_epochs=NUM_EPOCHS,\n",
    "    model=feature_extraction_model,\n",
    "    criterion=loss_fn,\n",
    "    optimizer=feature_extraction_optimizer,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6e21ffe",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_model(model, criterion, optimizer):\n",
    "    with torch.no_grad():\n",
    "        correct = 0\n",
    "        total = 0\n",
    "        for images, labels in tqdm(test_dataloader):\n",
    "            images = images.to(DEVICE)\n",
    "            labels = labels.to(DEVICE)\n",
    "            outputs = model(images)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "            del images, labels, outputs\n",
    "        print(f\"Testing Accuracy: {(correct/total)*100}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "259819c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_model(\n",
    "    model=feature_extraction_model,\n",
    "    criterion=loss_fn,\n",
    "    optimizer=feature_extraction_optimizer,\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
